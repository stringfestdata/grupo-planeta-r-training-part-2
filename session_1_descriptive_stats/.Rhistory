# Is there a relationship between len and supp?
len_supp_t_test <- tooth_growth %>%
t_test(len ~ supp, paired = FALSE)
len_supp_t_test
# Visualize results with paired boxplot
p <- ggboxplot(
tooth_growth, x = 'supp', y = 'len',
color = 'supp', ylim = c(0, 40))
# y_position = where on y-axis does this go?
p + stat_pvalue_manual(len_supp_t_test, label = 'p', y.position = 35)
## Paired sample t-test on sleep dataset
### Try exploring this dataset on your own
sleep %>%
group_by(group) %>%
get_summary_stats()
# Paired sample t-test
## Read in relevant dataset
tomography <- read_csv('https://raw.githubusercontent.com/stringfestdata/training-assets/master/datasets/tomography.csv')
tomography
tomography_paired <- tomography %>%
t_test(volume ~ period, paired = TRUE)
tomography_paired
## Visualize results of paired sample t-test
p <- ggpaired(
tomography, x = 'period', y = 'volume',
color = 'period', ylim = c(0, 8000))
p + stat_pvalue_manual(tomography_paired, label = 'p', y.position = 7500)
## Back to tooth_growth
# One way ANOVA
tooth_growth %>% anova_test(len ~ dose)
## Visualizing multi-pairwise:
### https://rpkgs.datanovia.com/rstatix/
# Two way ANOVA
tooth_growth %>% anova_test(len ~ supp * dose)
# Chi square
## Use the penguins dataset
### Use the tabyl function to get frequencies
data('penguins')
penguins %>%
drop_na()%>%
tabyl(island, sex) %>%
chisq.test()
## Correlation test
names(penguins)
penguins_select <- penguins %>%
select(bill_length_mm,
bill_depth_mm,
flipper_length_mm,
body_mass_g
)
# Correlation test between two variables
penguins_select %>% cor_test(flipper_length_mm, body_mass_g, method = "pearson")
# Correlation of one variable against all
penguins_select %>% cor_test(body_mass_g, method = "pearson")
# Pairwise correlation test between all variables
penguins_select %>% cor_test(method = "pearson")
# Correlation plot
penguins_corr <- mydata %>% cor_mat()
data('penguins')
penguins %>%
drop_na()%>%
tabyl(island, sex) %>%
chisq.test()
## Correlation test
names(penguins)
penguins_select <- penguins %>%
select(bill_length_mm,
bill_depth_mm,
flipper_length_mm,
body_mass_g
)
# Correlation test between two variables
penguins_select %>% cor_test(flipper_length_mm, body_mass_g, method = "pearson")
# Correlation of one variable against all
penguins_select %>% cor_test(body_mass_g, method = "pearson")
# Pairwise correlation test between all variables
penguins_select %>% cor_test(method = "pearson")
penguins_corr <- penguins_select %>% cor_mat()
penguins_corr
penguins_corr %>%
cor_reorder() %>%
pull_lower_triangle() %>%
cor_plot()
penguins_corr %>%
cor_reorder() %>%
pull_lower_triangle() %>%
cor_plot()
penguins_corr <- penguins_select %>% cor_mat()
penguins_corr
library(ggplot2)
data(package = 'ggplot2')
view(mpg)
autompg
library('ISLR')
install.packages('ISLR')
library('ISLR')
view(Auto)
library(tidyverse)
library(moderndive)
library(infer)
ggplot(pennies_sample, aes(x = year)) +
geom_histogram(binwidth = 10, color = "white")
x_bar <- pennies_sample %>%
summarize(mean_year = mean(year))
x_bar
# Resampled data
pennies_resamples
dim(pennies_resamples)
# What are the resampled means?
resampled_means <- pennies_resamples %>%
group_by(name) %>%
summarize(mean_year = mean(year))
resampled_means
ggplot(resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1, color = "white", boundary = 1990) +
labs(x = "Sampled mean year")
virtual_resample <- pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE)
virtual_resample %>%
summarize(resample_mean = mean(year))
# Virtually resample 35 times
virtual_resamples <- pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 35)
virtual_resamples
# Check each individual sample mean
virtual_resampled_means <- virtual_resamples %>%
group_by(replicate) %>%
summarize(mean_year = mean(year))
virtual_resampled_means
# Plot this as a histogram
ggplot(virtual_resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1, color = "white", boundary = 1990) +
labs(x = "Resample mean year")
# Combine these together
virtual_resampled_means <- pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 1000) %>%
group_by(replicate) %>%
summarize(mean_year = mean(year))
virtual_resampled_means
# Summarize mean of means
virtual_resampled_means %>%
summarize(mean_of_means = mean(mean_year))
# Summarize standard error
virtual_resampled_means %>%
summarize(SE = sd(mean_year))
pennies_sample %>%
specify(response = year) %>%
calculate(stat = "mean")
pennies_sample %>%
specify(response = year)
pennies_sample %>%
specify(response = year) %>%
generate(reps = 1000, type = "bootstrap")
bootstrap_distribution <- pennies_sample %>%
specify(response = year) %>%
generate(reps = 1000) %>%
calculate(stat = "mean")
bootstrap_distribution
percentile_ci <- bootstrap_distribution %>%
get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci
visualize(bootstrap_distribution)
visualize(bootstrap_distribution) +
shade_confidence_interval(endpoints = percentile_ci)
ggplot(evals_ch5,
aes(x = bty_avg, y = score)) +
geom_point() +
labs(x = 'Beauty Score',
y = 'Teaching Score',
title = 'Relationship between teaching
and beauty scores') +
geom_smooth(method = 'lm', se = FALSE)
evals_ch5 <- evals %>%
select(ID, score, bty_avg, age)
glimpse(evals_ch5)
ggplot(evals_ch5,
aes(x = bty_avg, y = score)) +
geom_point() +
labs(x = 'Beauty Score',
y = 'Teaching Score',
title = 'Relationship between teaching
and beauty scores') +
geom_smooth(method = 'lm', se = FALSE)
# Fit regression model:
score_model <- lm(score ~ bty_avg, data = evals_ch5)
# Get regression table:
get_regression_table(score_model)
# Fit regression model:
score_model <- lm(score ~ bty_avg, data = evals_ch5)
# Get regression points:
regression_points <- get_regression_points(score_model)
regression_points
## This data was collected by hand
glimpse(pennies_sample)
## This data was collected by hand
view(pennies)
## This data was collected by hand
head(pennies_sample)
ggplot(pennies_sample, aes(x = year)) +
geom_histogram(binwidth = 10)
#
x_bar <- pennies_sample %>%
summarize(mean_year = mean(year))
x_bar
# Resampled data
pennies_resamples
# Resampled data
View(pennies_resamples)
dim(pennies_sample)
dim(pennies_resamples)
# What are the resampled means?
resampled_means <- pennies_resamples %>%
group_by(name) %>%
summarize(mean_year = mean(year))
resampled_means
# Visualize distribution of sample means
ggplot(resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1) +
labs(x = "Sampled mean year")
# Visualize distribution of sample means
ggplot(resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1, boundary = 1990) +
labs(x = "Sampled mean year")
# Visualize distribution of sample means
ggplot(resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1) +
labs(x = "Sampled mean year")
virtual_resample <- pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE)
virtual_resample %>%
summarize(resample_mean = mean(year))
# Virtually resample 35 times
virtual_resamples <- pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 35)
virtual_resamples
# Check each individual sample mean
virtual_resampled_means <- virtual_resamples %>%
group_by(replicate) %>%
summarize(mean_year = mean(year))
virtual_resampled_means
# Plot this as a histogram
ggplot(virtual_resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1, color = "white", boundary = 1990) +
labs(x = "Resample mean year")
# Combine these together
virtual_resampled_means <- pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 1000) %>%
group_by(replicate) %>%
summarize(mean_year = mean(year))
# Plot this as a histogram
ggplot(virtual_resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1, color = "white", boundary = 1990) +
labs(x = "Resample mean year")
# Plot this as a histogram
ggplot(virtual_resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1) +
labs(x = "Resample mean year")
# Summarize mean of means
virtual_resampled_means %>%
summarize(mean_of_means = mean(mean_year))
# Summarize standard error
virtual_resampled_means %>%
summarize(SE = sd(mean_year))
pennies_sample %>%
specify(response = year) %>%
calculate(stat = "mean")
## Calculate confidence interval ##
pennies_sample %>%
specify(response = year) %>%
calculate(stat = "mean")
pennies_sample %>%
specify(response = year)
pennies_sample %>%
specify(response = year) %>%
generate(reps = 1000, type = "bootstrap")
bootstrap_distribution <- pennies_sample %>%
specify(response = year) %>%
generate(reps = 1000) %>%
calculate(stat = "mean")
bootstrap_distribution
percentile_ci <- bootstrap_distribution %>%
get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci
visualize(bootstrap_distribution)
visualize(bootstrap_distribution) +
shade_confidence_interval(endpoints = percentile_ci)
### Go back to original dataset and use infer
## Calculate confidence interval ##
pennies_sample %>%
specify(response = year) %>%
calculate(stat = 'mean')
# Create a bootstrap
# resample the pennies with replacement 1,000 times
pennies_sample %>%
specify(response = year) %>%
generate(reps = 1000, type = 'bootstrap')
# Now find the mean
bootstrap_distribution <- pennies_sample %>%
specify(response = year) %>%
generate(reps = 1000) %>%
calculate(stat = 'mean')
bootstrap_distribution
# Find bootstrap confidence range
percentile_ci <- bootstrap_distribution %>%
get_confidence_interval(level = 0.95, type = 'percentile')
percentile_ci
visualize(bootstrap_distribution)
visualize(bootstrap_distribution) +
shade_confidence_interval(endpoints = percentile_ci)
evals_ch5 <- evals %>%
select(ID, score, bty_avg, age)
glimpse(evals_ch5)
ggplot(evals_ch5,
aes(x = bty_avg, y = score)) +
geom_point() +
labs(x = 'Beauty Score',
y = 'Teaching Score',
title = 'Relationship between teaching
and beauty scores') +
geom_smooth(method = 'lm', se = FALSE)
# Fit regression model:
score_model <- lm(score ~ bty_avg, data = evals_ch5)
# Get regression table:
get_regression_table(score_model)
# Get regression table:
get_regression_table(score_model)
# Fit regression model:
score_model <- lm(score ~ bty_avg, data = evals_ch5)
# Get regression table:
get_regression_table(score_model)
# Fit regression model:
score_model <- lm(score ~ bty_avg, data = evals_ch5)
# Get regression table:
get_regression_table(score_model)
# Get regression points:
regression_points <- get_regression_points(score_model)
regression_points
bootstrap_distn_slope <- evals_ch5 %>%
specify(formula = score ~ bty_avg) %>%
generate(reps = 1000, type = 'bootstrap') %>%
calculate(stat = 'slope')
bootstrap_distn_slope
# visualize bootstrap
visualize(bootstrap_distn_slope)
# Get confidence interval
percentile_ci <- bootstrap_distn_slope %>%
get_confidence_interval(type = "percentile", level = 0.95)
# Get confidence interval
percentile_ci <- bootstrap_distn_slope %>%
get_confidence_interval(type = 'percentile', level = 0.95)
percentile_ci
# Visualize bootstrap
visualize(bootstrap_distn_slope) +
shade_confidence_interval(endpoints = percentile_ci, fill = NULL,
linetype = "solid", color = "grey90") +
shade_confidence_interval(endpoints = se_ci, fill = NULL,
linetype = "dashed", color = "grey60") +
shade_confidence_interval(endpoints = c(0.035, 0.099), fill = NULL,
linetype = "dotted", color = "black")
# Get confidence interval
percentile_ci <- bootstrap_distn_slope %>%
get_confidence_interval(type = 'percentile', level = 0.95)
percentile_ci
# Visualize bootstrap
visualize(bootstrap_distn_slope) +
shade_confidence_interval(endpoints = percentile_ci, fill = NULL,
linetype = "solid", color = "grey90")
# Add bootstrap slope
null_distn_slope <- evals %>%
specify(score ~ bty_avg) %>%
hypothesize(null = 'independence') %>%
generate(reps = 1000, type = 'permute') %>%
calculate(stat = 'slope')
null_distn_slope
null_distn_slope %>%
get_p_value(obs_stat = observed_slope, direction = "both")
observed_slope <- evals %>%
specify(score ~ bty_avg) %>%
calculate(stat = 'slope')
observed_slope
null_distn_slope %>%
get_p_value(obs_stat = observed_slope, direction = "both")
# Ch8.4.2 - confidence intervals of Modern Dive
library(tidyverse)
library(moderndive)
library(infer)
# What is average year of US pennies in 2019?
## This data was collected by hand
## by going to the bank
head(pennies_sample)
ggplot(pennies_sample, aes(x = year)) +
geom_histogram(binwidth = 10)
# Get a point estimate
x_bar <- pennies_sample %>%
summarize(mean_year = mean(year))
x_bar
# Resample 50 pennies from our
# original sample of 50 pennies.
View(pennies_resamples)
dim(pennies_sample)
dim(pennies_resamples)
# What are the resampled means?
resampled_means <- pennies_resamples %>%
group_by(name) %>%
summarize(mean_year = mean(year))
resampled_means
# Visualize distribution of sample means
ggplot(resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1) +
labs(x = "Sampled mean year")
# Bootstrap resampling with replacement
# Computational resampling
virtual_resample <- pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE)
# Find the average year
virtual_resample %>%
summarize(resample_mean = mean(year))
# Virtually resample 35 times
virtual_resamples <- pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 35)
virtual_resamples
# Check each individual sample mean
virtual_resampled_means <- virtual_resamples %>%
group_by(replicate) %>%
summarize(mean_year = mean(year))
virtual_resampled_means
# Plot this as a histogram
ggplot(virtual_resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1) +
labs(x = "Resample mean year")
# Summarize mean of means
virtual_resampled_means %>%
summarize(mean_of_means = mean(mean_year))
# Summarize standard error
virtual_resampled_means %>%
summarize(SE = sd(mean_year))
### Go back to original dataset and use infer
## Calculate confidence interval ##
pennies_sample %>%
specify(response = year) %>%
calculate(stat = 'mean')
# Create a bootstrap
# resample the pennies with replacement 1,000 times
pennies_sample %>%
specify(response = year) %>%
generate(reps = 1000, type = 'bootstrap')
# Now find the mean
bootstrap_distribution <- pennies_sample %>%
specify(response = year) %>%
generate(reps = 1000) %>%
calculate(stat = 'mean')
bootstrap_distribution
# Find bootstrap confidence range
percentile_ci <- bootstrap_distribution %>%
get_confidence_interval(level = 0.95, type = 'percentile')
percentile_ci
visualize(bootstrap_distribution)
visualize(bootstrap_distribution) +
shade_confidence_interval(endpoints = percentile_ci)
### Move to regression inference
evals_ch5 <- evals %>%
select(ID, score, bty_avg, age)
glimpse(evals_ch5)
ggplot(evals_ch5,
aes(x = bty_avg, y = score)) +
geom_point() +
labs(x = 'Beauty Score',
y = 'Teaching Score',
title = 'Relationship between teaching
and beauty scores') +
geom_smooth(method = 'lm', se = FALSE)
# Fit regression model:
score_model <- lm(score ~ bty_avg, data = evals_ch5)
# Get regression table:
get_regression_table(score_model)
# Fit regression model:
score_model <- lm(score ~ bty_avg, data = evals_ch5)
# Get regression points:
## What are these?
regression_points <- get_regression_points(score_model)
regression_points
# Find bootstrap distribution
# for slope
bootstrap_distn_slope <- evals_ch5 %>%
specify(formula = score ~ bty_avg) %>%
generate(reps = 1000, type = 'bootstrap') %>%
calculate(stat = 'slope')
bootstrap_distn_slope
# visualize bootstrap
visualize(bootstrap_distn_slope)
# Get confidence interval
percentile_ci <- bootstrap_distn_slope %>%
get_confidence_interval(type = 'percentile', level = 0.95)
percentile_ci
# Visualize bootstrap
visualize(bootstrap_distn_slope) +
shade_confidence_interval(endpoints = percentile_ci, fill = NULL,
linetype = "solid", color = "grey90")
# Add bootstrap slope
null_distn_slope <- evals %>%
specify(score ~ bty_avg) %>%
hypothesize(null = 'independence') %>%
generate(reps = 1000, type = 'permute') %>%
calculate(stat = 'slope')
null_distn_slope
observed_slope <- evals %>%
specify(score ~ bty_avg) %>%
calculate(stat = 'slope')
observed_slope
# Get p-value
null_distn_slope %>%
get_p_value(obs_stat = observed_slope, direction = "both")
